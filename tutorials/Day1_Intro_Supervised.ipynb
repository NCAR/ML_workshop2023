{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e621a632-b898-4621-91cd-a7473b514c51",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Supervised learning is dependent on labeled training data. The primary goal of supervised learning is to learn a mapping from input data to the desired target through a process of training. Target data, or labels, can take form as  continuous values (regression problems) or discrete numerical or categorical (classification) values. **Broadly, the goal is to iteravely inform the parameters of your model by optimizing a chosen cost function (loss function / objective function) over your target data**. There are many cost functions to choose from, especially once you get into customized neural networks. However, many tried-and-true methods perform well with Mean Squared Error (MSE) and binary cross entropy (log loss) for regression and classification, respectively.\n",
    "\n",
    "### What does training data look like?\n",
    "\n",
    "Traininig data can come in a variety of shapes and sizes, such as images or timeseries, and many custom architectures can handle different shapes of data. However, the sklearn framework expects a strict 2D matrix for the input data - the rows reresent an individual sample, and each column represents an indivual **feature**. Although neural networks (such as Convolutional Networks which are common use cases for image data) can handle 3D+ data as input, whereas sklearn models cannot, this does not necessarily mean you can't use n-dimentional data for input - you can flatten whichever dimensions you'd like to conform to the 2D format expected. In the image case, this would just mean flattening each 2D image into a 1D vector, thus making each pixel it's own feature. For example, flattening a set of 32 x 32 images for input into a model would result in a data shape of (n_images, 1024). \n",
    "\n",
    "#### Labels / Targets\n",
    "\n",
    "Each input sample requires an associated target (label) which is used to evaluate its performance during training. These can be observations, modeled data, hand labeled, etc, really anything. And of course, your model will inhereit the biases of the training data (both input and target data), so thoughtful consideration of what your training data looks like is important.\n",
    "\n",
    "### Model fit (underfitting vs overfitting)\n",
    "\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "* Reshaping\n",
    "* Scaling - why do it?\n",
    "    * What are advantages / disadvantages of differnt methods? \n",
    "* Data partitioning - why do it?\n",
    "* How to treat categorical variables\n",
    "    * One-hot encoding\n",
    " \n",
    "## Evaluation / Verification\n",
    " \n",
    "#### The goal is to generalize to unseen data.\n",
    " \n",
    "### Discussion of Data Challenges in ML\n",
    "\n",
    "### Introduce SARS Atmospheric Data\n",
    "\n",
    "Scale / partition\n",
    "\n",
    "### Train binary classifier with two features and plot decision boundaries \n",
    "\n",
    "### Frame hail problem as classifyier (big / small hail) and train a logistic regression model\n",
    "\n",
    "#### Plot decision boundaries and do basic eval\n",
    "\n",
    "Small demonstration of an overfit / underfit model\n",
    "\n",
    "### Train model as a regression problem and eval\n",
    "\n",
    "### (potentially generate new samples from a GMM and retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9ea381-113d-47c1-ba88-2ec73081f20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4457f8-07ae-4347-bcfc-b360b80fcb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
